{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169726c1-d887-469b-a4ff-a2d7de1ff4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a90ac0e2-18c2-4a74-b28b-9d502c73d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /cluster/home/larsira/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7682e-04, 4.8932e-04, 4.4337e-04, 2.2192e-04, 3.6700e-04, 5.6111e-04,\n",
      "        2.8973e-04, 1.1747e-03, 9.3086e-04, 3.6478e-04, 3.1319e-04, 3.6052e-04,\n",
      "        4.5311e-04, 3.3355e-04, 2.5259e-04, 5.1988e-04, 3.4693e-04, 6.5938e-04,\n",
      "        5.8294e-04, 4.0553e-04, 2.7157e-04, 4.3501e-04, 1.9792e-04, 8.4356e-04,\n",
      "        2.4034e-04, 2.9130e-04, 3.1035e-04, 3.4033e-04, 3.6154e-04, 4.5125e-04,\n",
      "        3.5851e-04, 3.1706e-04, 4.2587e-04, 4.0407e-04, 5.7369e-04, 3.1102e-04,\n",
      "        1.0691e-03, 4.5449e-04, 4.7903e-04, 7.3533e-04, 3.5706e-04, 5.3187e-04,\n",
      "        4.1060e-04, 5.1288e-04, 4.4074e-04, 6.9175e-04, 4.5572e-04, 4.0864e-04,\n",
      "        1.8632e-04, 2.5844e-04, 3.3573e-04, 1.0695e-03, 7.9689e-04, 6.1170e-04,\n",
      "        6.1090e-04, 3.4405e-04, 4.4470e-04, 3.1356e-04, 6.2599e-04, 7.5916e-04,\n",
      "        1.8187e-03, 6.6304e-04, 8.0283e-04, 6.5706e-04, 6.2739e-04, 6.8057e-04,\n",
      "        6.8777e-04, 5.9143e-04, 3.8019e-04, 3.3051e-04, 2.7212e-04, 7.6540e-04,\n",
      "        2.5510e-04, 5.8679e-04, 3.1696e-04, 3.2044e-04, 7.4866e-04, 5.5523e-04,\n",
      "        1.4603e-03, 7.5287e-04, 3.5196e-04, 2.0536e-04, 7.9731e-04, 3.5603e-04,\n",
      "        4.3115e-04, 6.7258e-04, 9.8985e-04, 1.1792e-03, 7.5369e-04, 4.2415e-04,\n",
      "        3.2551e-04, 2.8174e-04, 1.8448e-04, 5.1940e-04, 6.1291e-04, 1.7828e-04,\n",
      "        3.9842e-04, 3.8526e-04, 1.7829e-04, 5.4382e-04, 2.5427e-04, 4.1061e-04,\n",
      "        3.6990e-04, 6.4673e-04, 8.2977e-04, 2.8029e-04, 4.4288e-04, 2.2067e-04,\n",
      "        3.1554e-04, 2.5008e-04, 1.8855e-04, 3.4257e-04, 2.1285e-03, 1.0624e-03,\n",
      "        8.2579e-04, 2.3352e-04, 2.9390e-04, 4.9537e-04, 1.1560e-03, 5.6919e-04,\n",
      "        2.7394e-04, 8.0581e-04, 8.4828e-04, 7.3652e-04, 1.6732e-03, 6.2953e-04,\n",
      "        8.7475e-04, 2.0972e-04, 2.0210e-04, 2.6339e-04, 2.7109e-04, 2.1249e-04,\n",
      "        4.0137e-04, 2.3290e-04, 4.6232e-04, 2.2947e-04, 4.1056e-04, 2.6075e-04,\n",
      "        2.3102e-04, 1.8804e-04, 2.1526e-04, 1.6842e-04, 1.1601e-04, 2.0504e-04,\n",
      "        3.8947e-04, 5.5268e-04, 2.7803e-04, 1.5137e-04, 2.0772e-04, 1.4999e-04,\n",
      "        7.8679e-04, 3.2799e-03, 4.5605e-04, 5.9460e-04, 8.0410e-04, 1.1635e-03,\n",
      "        7.8713e-04, 1.0980e-03, 1.0943e-03, 1.0520e-03, 1.1148e-03, 1.1407e-03,\n",
      "        1.0410e-03, 1.8153e-03, 9.9344e-04, 5.8839e-04, 7.0414e-04, 5.9974e-04,\n",
      "        1.2414e-03, 9.0749e-04, 8.4116e-04, 1.7215e-03, 1.4131e-03, 1.2469e-03,\n",
      "        8.4244e-04, 5.2691e-04, 1.0214e-03, 7.1370e-04, 1.3354e-03, 1.0271e-03,\n",
      "        1.1159e-03, 9.1977e-04, 1.1645e-03, 9.0577e-04, 1.6678e-03, 1.6931e-03,\n",
      "        1.7527e-03, 1.1854e-03, 1.1083e-03, 1.3749e-03, 4.6795e-04, 1.5204e-03,\n",
      "        1.1052e-03, 1.1446e-03, 3.6783e-04, 1.6202e-03, 8.4260e-04, 1.0254e-03,\n",
      "        8.3411e-04, 1.1784e-03, 1.0212e-03, 7.8201e-04, 1.3616e-03, 1.4699e-03,\n",
      "        9.7941e-04, 6.9935e-04, 6.6951e-04, 1.5036e-03, 2.3188e-03, 9.3017e-04,\n",
      "        7.0577e-04, 1.4353e-03, 1.2410e-03, 9.7217e-04, 7.2936e-04, 1.2053e-03,\n",
      "        1.1555e-03, 8.7684e-04, 7.5624e-04, 1.2819e-03, 1.2328e-03, 7.7664e-04,\n",
      "        9.6878e-04, 1.6882e-03, 7.9983e-04, 1.1060e-03, 1.1103e-03, 1.6850e-03,\n",
      "        6.4939e-04, 8.0922e-04, 7.1246e-04, 1.5164e-03, 1.0153e-03, 6.1639e-04,\n",
      "        1.2695e-03, 1.3464e-03, 1.4779e-03, 1.0488e-03, 1.5690e-03, 7.8317e-04,\n",
      "        1.3930e-03, 1.0378e-03, 1.3533e-03, 9.3082e-04, 6.0609e-04, 1.0325e-03,\n",
      "        1.0250e-03, 9.7589e-04, 1.6240e-03, 8.5803e-04, 1.1936e-03, 2.3277e-03,\n",
      "        4.9408e-04, 1.5269e-03, 1.3532e-03, 4.1185e-04, 1.2497e-03, 1.1438e-03,\n",
      "        1.0012e-03, 1.0480e-03, 5.1105e-04, 4.3153e-04, 7.0955e-04, 1.1406e-03,\n",
      "        1.0632e-03, 1.5192e-03, 1.0317e-03, 1.1946e-03, 7.1432e-04, 4.4400e-04,\n",
      "        5.2598e-04, 4.1529e-04, 6.8745e-04, 1.7902e-03, 3.8173e-04, 3.8565e-04,\n",
      "        4.2334e-04, 4.2886e-04, 2.9411e-04, 5.8941e-04, 7.0121e-04, 2.2475e-03,\n",
      "        2.4956e-03, 8.1386e-04, 1.3412e-03, 2.1024e-03, 6.0302e-04, 9.5184e-04,\n",
      "        5.3726e-04, 2.0296e-04, 3.6809e-04, 3.0865e-04, 7.3633e-04, 3.0898e-04,\n",
      "        3.2467e-04, 3.1401e-04, 3.8189e-04, 2.2816e-04, 6.2211e-04, 8.4884e-04,\n",
      "        2.3925e-04, 3.7030e-04, 3.9899e-04, 5.2582e-04, 2.9552e-04, 3.3124e-04,\n",
      "        9.4502e-04, 3.6717e-04, 2.5438e-04, 6.3609e-04, 1.1119e-03, 7.0109e-04,\n",
      "        6.2700e-04, 1.0562e-03, 1.6695e-03, 6.3503e-04, 3.0547e-04, 2.2685e-04,\n",
      "        2.8235e-04, 5.0455e-04, 2.0979e-04, 3.4966e-04, 2.8319e-04, 2.2849e-04,\n",
      "        2.8300e-04, 2.3591e-04, 3.0904e-04, 9.5118e-04, 5.6830e-04, 3.8133e-04,\n",
      "        9.0814e-04, 8.5138e-04, 7.3850e-04, 9.7009e-04, 6.3159e-04, 4.1663e-04,\n",
      "        2.6578e-04, 7.8463e-04, 1.0538e-03, 2.2983e-04, 5.5406e-04, 1.1777e-03,\n",
      "        5.7473e-04, 2.7380e-04, 2.1058e-04, 1.0407e-03, 3.8142e-04, 1.9032e-04,\n",
      "        6.2896e-04, 1.9829e-04, 2.8668e-04, 1.1790e-04, 3.3137e-04, 5.5587e-04,\n",
      "        3.6509e-04, 1.0708e-03, 3.1933e-03, 8.6401e-04, 1.3376e-03, 1.3692e-03,\n",
      "        5.9755e-04, 1.3779e-03, 1.0253e-03, 9.0608e-04, 4.3787e-04, 3.7576e-04,\n",
      "        2.2162e-04, 4.3697e-04, 3.7775e-04, 3.9476e-04, 5.6931e-04, 8.1193e-04,\n",
      "        3.4431e-04, 9.5390e-04, 4.7399e-04, 3.7655e-04, 2.5210e-04, 9.1928e-04,\n",
      "        5.9155e-04, 3.9348e-04, 1.1971e-03, 5.9444e-04, 6.0242e-04, 5.9593e-04,\n",
      "        3.8005e-04, 4.2281e-04, 2.1775e-04, 3.1874e-04, 2.5794e-04, 4.4700e-04,\n",
      "        7.6078e-04, 7.0663e-04, 2.5849e-04, 1.7279e-04, 4.2324e-04, 7.2478e-04,\n",
      "        4.3804e-04, 3.4556e-04, 9.7281e-04, 7.3726e-04, 4.0511e-04, 1.4283e-03,\n",
      "        7.0688e-04, 1.0648e-04, 1.5049e-04, 4.6134e-04, 4.0229e-04, 5.6329e-04,\n",
      "        4.5445e-04, 2.0341e-03, 4.8649e-04, 7.8502e-04, 3.6079e-03, 1.0808e-03,\n",
      "        1.1149e-03, 1.6190e-03, 5.3534e-04, 1.7039e-03, 6.8109e-04, 2.2380e-03,\n",
      "        1.6398e-03, 1.6081e-03, 7.6765e-04, 8.5281e-04, 7.1797e-04, 3.9176e-04,\n",
      "        1.2734e-03, 2.6391e-03, 3.5693e-03, 1.4990e-03, 5.9650e-04, 6.5286e-04,\n",
      "        1.0974e-03, 1.0524e-03, 1.4574e-03, 1.7526e-03, 6.4659e-04, 4.6094e-04,\n",
      "        1.0939e-03, 8.2555e-04, 1.4511e-03, 6.4992e-04, 7.2350e-04, 5.3403e-04,\n",
      "        5.4681e-04, 7.7754e-04, 7.6377e-04, 2.9076e-03, 1.7004e-03, 3.9291e-04,\n",
      "        4.7886e-04, 8.4293e-04, 1.4302e-03, 6.5777e-04, 7.4459e-04, 1.2860e-03,\n",
      "        2.1294e-03, 2.6644e-03, 5.8855e-04, 1.5296e-03, 3.8490e-04, 1.3135e-03,\n",
      "        2.4727e-03, 6.0268e-03, 1.2472e-03, 6.2250e-04, 2.2576e-04, 8.8089e-04,\n",
      "        6.5295e-04, 2.7826e-03, 1.6832e-03, 1.1067e-03, 7.2062e-04, 1.6061e-03,\n",
      "        5.4004e-04, 7.9045e-04, 7.7389e-04, 1.0944e-03, 1.5809e-03, 1.1696e-03,\n",
      "        8.1706e-04, 8.8411e-04, 6.6333e-04, 3.7540e-04, 2.6574e-04, 4.9399e-04,\n",
      "        4.7389e-04, 2.2653e-03, 3.0130e-03, 1.6842e-03, 1.0699e-03, 1.3979e-03,\n",
      "        9.7820e-04, 3.2698e-04, 2.0671e-03, 2.8435e-04, 6.6610e-04, 6.2358e-04,\n",
      "        5.9365e-04, 2.7040e-03, 1.8575e-04, 1.7597e-03, 1.7303e-03, 1.1765e-03,\n",
      "        1.7346e-03, 1.3607e-03, 1.3246e-03, 1.0932e-03, 1.4873e-03, 7.1492e-04,\n",
      "        3.1674e-04, 4.0489e-04, 1.7446e-03, 7.2068e-04, 1.9940e-03, 3.7174e-03,\n",
      "        1.0122e-03, 9.2533e-04, 2.0842e-03, 2.1764e-03, 3.4705e-04, 1.0191e-03,\n",
      "        1.3678e-03, 4.4327e-03, 8.3972e-04, 3.8959e-04, 9.1216e-04, 4.2901e-04,\n",
      "        1.0044e-03, 8.8022e-04, 1.9389e-03, 1.0735e-03, 8.5374e-04, 3.8888e-04,\n",
      "        1.4465e-03, 4.4866e-04, 4.9549e-04, 3.6364e-04, 6.6654e-04, 2.5353e-03,\n",
      "        2.9634e-04, 2.1558e-03, 2.0519e-03, 1.2774e-03, 1.0670e-03, 1.9695e-03,\n",
      "        1.0149e-03, 1.2767e-04, 2.9881e-04, 7.1106e-04, 5.0653e-04, 9.7794e-04,\n",
      "        2.2145e-03, 7.3434e-04, 2.6065e-04, 3.8553e-04, 1.2321e-03, 1.2491e-03,\n",
      "        1.8334e-03, 2.2175e-03, 6.6596e-04, 7.3878e-04, 1.1727e-03, 5.4213e-04,\n",
      "        2.8598e-04, 3.5301e-04, 9.3800e-04, 1.9234e-03, 1.0834e-03, 4.8799e-04,\n",
      "        1.7903e-03, 6.8416e-04, 1.7433e-03, 2.3282e-04, 1.5581e-03, 7.7509e-04,\n",
      "        2.8912e-04, 1.8079e-03, 1.3798e-03, 7.3750e-04, 1.0263e-03, 5.3379e-04,\n",
      "        1.4184e-03, 1.5558e-03, 8.4097e-04, 1.3240e-03, 4.6328e-04, 3.3987e-03,\n",
      "        1.1947e-03, 2.1936e-03, 5.8191e-04, 1.5327e-03, 2.6046e-04, 1.6526e-03,\n",
      "        1.2618e-03, 3.8343e-04, 2.3519e-03, 5.2012e-04, 5.1706e-04, 1.5864e-03,\n",
      "        6.6620e-03, 9.3105e-04, 4.9678e-04, 4.7455e-04, 1.1129e-03, 1.1018e-03,\n",
      "        1.8865e-03, 6.1224e-04, 1.4652e-03, 4.9954e-04, 1.8755e-03, 1.4997e-03,\n",
      "        5.5704e-04, 1.3350e-03, 6.3566e-04, 7.8653e-04, 1.4931e-03, 1.9750e-03,\n",
      "        3.8536e-03, 1.6190e-03, 2.5454e-03, 1.5373e-03, 1.3476e-03, 1.1841e-03,\n",
      "        7.9435e-04, 3.6692e-04, 1.6872e-03, 5.1828e-04, 3.7141e-04, 7.2683e-04,\n",
      "        6.8025e-04, 1.4583e-03, 2.0159e-03, 2.2138e-03, 6.0426e-04, 1.0118e-03,\n",
      "        1.6706e-03, 1.4325e-03, 2.2008e-03, 1.0082e-03, 1.8040e-04, 2.2780e-03,\n",
      "        7.8853e-04, 3.1023e-03, 1.4093e-03, 4.0286e-04, 1.4251e-03, 1.1482e-03,\n",
      "        3.7929e-04, 3.2892e-04, 1.5339e-03, 7.0692e-04, 1.4276e-03, 1.8015e-03,\n",
      "        6.7576e-04, 1.3763e-03, 8.6164e-04, 7.7098e-04, 7.6237e-04, 1.0954e-03,\n",
      "        9.3762e-04, 3.4673e-04, 6.2765e-04, 3.0915e-04, 1.7066e-03, 7.7492e-04,\n",
      "        2.3208e-03, 1.4148e-03, 3.2019e-04, 5.0274e-04, 1.0392e-03, 5.7662e-04,\n",
      "        7.9071e-04, 1.4483e-03, 2.4196e-03, 3.6630e-04, 3.1580e-03, 1.8760e-03,\n",
      "        1.6260e-03, 6.2247e-04, 1.4369e-03, 1.4802e-03, 5.4875e-04, 1.1151e-03,\n",
      "        9.4957e-04, 2.1203e-04, 3.9635e-04, 2.6960e-04, 7.2815e-04, 3.4518e-04,\n",
      "        3.2970e-04, 1.5405e-03, 1.7157e-03, 1.2501e-03, 3.4235e-04, 1.3723e-03,\n",
      "        2.3614e-03, 6.7949e-04, 4.6868e-04, 1.2959e-03, 6.0001e-03, 7.4935e-04,\n",
      "        5.0174e-04, 1.2963e-03, 1.0583e-03, 6.8552e-04, 5.6579e-04, 1.0586e-03,\n",
      "        1.6270e-03, 6.8850e-04, 1.2838e-03, 1.1077e-03, 6.9860e-04, 6.2123e-04,\n",
      "        1.1411e-03, 3.9650e-04, 1.4340e-03, 4.0672e-04, 7.4978e-04, 1.0340e-03,\n",
      "        1.0293e-03, 1.0507e-03, 2.3737e-03, 9.3040e-04, 3.6782e-04, 2.0992e-03,\n",
      "        3.4838e-04, 6.3552e-04, 3.4015e-03, 4.3305e-04, 6.4889e-04, 4.8378e-03,\n",
      "        4.1550e-04, 3.8963e-03, 2.1736e-04, 8.4626e-04, 7.7576e-04, 1.4880e-03,\n",
      "        2.0580e-03, 9.3839e-04, 1.8881e-03, 6.6263e-04, 1.4892e-03, 8.5117e-04,\n",
      "        1.0325e-03, 5.9131e-04, 8.5157e-04, 1.3361e-03, 1.1229e-03, 2.3966e-03,\n",
      "        1.3244e-03, 4.3105e-04, 1.1999e-03, 1.8715e-03, 1.4737e-03, 4.4378e-04,\n",
      "        1.5428e-03, 7.3623e-04, 1.9736e-03, 7.1000e-04, 1.0502e-03, 1.9701e-03,\n",
      "        1.3746e-03, 9.2927e-04, 1.9581e-03, 1.5498e-03, 8.4694e-04, 1.2584e-03,\n",
      "        6.8435e-04, 2.8998e-03, 1.4054e-03, 9.1116e-04, 2.2352e-03, 1.6158e-03,\n",
      "        1.3071e-03, 1.1107e-03, 9.7417e-04, 8.3760e-04, 3.1856e-03, 4.7543e-04,\n",
      "        3.6775e-04, 4.2406e-04, 2.0029e-03, 2.0349e-03, 2.6894e-03, 1.1451e-03,\n",
      "        1.6157e-03, 1.5339e-03, 8.2596e-04, 1.1704e-03, 1.1954e-03, 2.0044e-03,\n",
      "        2.7541e-03, 1.8794e-03, 9.4807e-04, 7.8652e-04, 1.6773e-03, 1.8242e-03,\n",
      "        3.0683e-04, 1.6301e-03, 5.2424e-04, 7.8073e-04, 2.3034e-04, 3.1189e-04,\n",
      "        1.7273e-03, 2.4634e-03, 9.9246e-04, 9.9168e-04, 2.5853e-03, 7.1816e-04,\n",
      "        6.2889e-04, 1.9689e-03, 5.4331e-04, 3.3486e-03, 2.9070e-04, 7.5053e-04,\n",
      "        1.0105e-03, 3.3800e-04, 2.9539e-03, 8.9988e-04, 1.6388e-04, 3.1442e-04,\n",
      "        1.0519e-03, 1.4039e-03, 1.8734e-03, 4.1660e-04, 1.1763e-03, 1.9606e-03,\n",
      "        2.9256e-03, 4.1805e-04, 2.2477e-03, 1.2079e-03, 3.8283e-04, 2.9399e-04,\n",
      "        9.9552e-04, 8.4878e-04, 3.6435e-03, 3.8956e-03, 1.6839e-03, 4.8650e-04,\n",
      "        2.7414e-03, 1.5469e-03, 1.1318e-03, 1.0123e-03, 9.5890e-04, 2.3681e-03,\n",
      "        1.5242e-03, 4.5493e-04, 8.4381e-04, 1.2626e-03, 2.2411e-03, 3.0647e-03,\n",
      "        5.2542e-03, 4.9473e-04, 7.0855e-04, 1.7461e-03, 3.5204e-04, 5.0262e-04,\n",
      "        7.8935e-04, 1.6637e-03, 1.2184e-03, 2.2757e-03, 1.6261e-03, 6.9231e-04,\n",
      "        4.4728e-04, 1.2000e-03, 9.6560e-04, 5.0258e-04, 2.6831e-03, 8.3744e-04,\n",
      "        1.5492e-03, 2.4295e-04, 2.5244e-03, 3.6865e-04, 9.3130e-05, 8.4353e-04,\n",
      "        3.0412e-03, 6.6772e-04, 6.8871e-04, 3.0170e-03, 2.0799e-03, 6.2167e-04,\n",
      "        1.9765e-03, 2.0397e-03, 7.7113e-04, 1.1408e-03, 5.8107e-04, 5.2203e-04,\n",
      "        3.2546e-04, 1.2434e-03, 3.3160e-04, 7.5461e-04, 1.4475e-03, 5.2224e-04,\n",
      "        5.4445e-04, 3.0818e-04, 1.2326e-03, 1.3028e-03, 3.8763e-03, 3.8924e-03,\n",
      "        2.7861e-04, 4.5350e-04, 3.5533e-03, 2.0034e-03, 1.9822e-03, 8.8451e-04,\n",
      "        6.7526e-04, 1.6870e-03, 3.0548e-04, 1.4644e-03, 2.9119e-03, 1.7179e-03,\n",
      "        1.5781e-03, 4.1643e-04, 1.7934e-04, 5.1335e-04, 1.1215e-03, 1.1204e-03,\n",
      "        1.2385e-03, 9.0281e-04, 6.7958e-04, 2.5276e-03, 4.1113e-04, 1.2346e-03,\n",
      "        6.4652e-04, 4.0712e-04, 3.0638e-04, 4.2822e-04, 6.2056e-04, 2.4421e-03,\n",
      "        6.3601e-04, 7.0072e-04, 1.2148e-03, 1.8790e-04, 8.9705e-04, 5.1098e-04,\n",
      "        1.1996e-03, 1.2335e-03, 9.6213e-04, 8.0600e-04, 6.0347e-04, 5.9121e-04,\n",
      "        1.0932e-03, 1.2016e-03, 6.7160e-04, 4.0214e-04, 3.8490e-04, 1.1821e-03,\n",
      "        1.6481e-03, 6.6807e-04, 1.0998e-03, 5.9041e-04, 6.6957e-04, 9.7754e-04,\n",
      "        1.6362e-03, 5.2439e-04, 6.1934e-04, 6.0572e-04, 7.2412e-04, 3.5623e-04,\n",
      "        5.5594e-04, 8.5168e-04, 5.0416e-04, 4.0281e-04, 3.3021e-04, 5.7636e-04,\n",
      "        1.3615e-03, 5.5039e-04, 1.9611e-03, 8.1782e-04, 7.6558e-04, 2.1028e-03,\n",
      "        6.6262e-04, 5.6618e-04, 1.9337e-04, 1.5831e-03, 1.9849e-04, 1.2493e-03,\n",
      "        8.4904e-04, 2.9270e-04, 3.8053e-04, 7.0982e-04, 1.2410e-03, 5.4479e-04,\n",
      "        4.3394e-04, 4.7223e-04, 1.4478e-04, 3.6374e-03, 9.1366e-04, 5.0600e-04,\n",
      "        6.3161e-04, 3.8436e-04, 2.8375e-04, 1.4579e-04, 4.4680e-04, 7.0329e-04,\n",
      "        1.0716e-03, 4.6994e-04, 1.9343e-03, 2.2751e-03], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True)\n",
    "\n",
    "image = Image.open(\"bombon.jpg\")\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = image_transforms(image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to(\"cuda\")\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a29ac55-6bff-4a7c-91b8-bcafbfccfccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-27 19:03:07--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: ‘imagenet_classes.txt’\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-01-27 19:03:08 (378 KB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e435e91-769e-4cd4-b0ce-726f137a9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook 0.0066620102152228355\n",
      "bucket 0.006026797462254763\n",
      "paper towel 0.006000073626637459\n",
      "tennis ball 0.005254208110272884\n",
      "plunger 0.004837784916162491\n"
     ]
    }
   ],
   "source": [
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
