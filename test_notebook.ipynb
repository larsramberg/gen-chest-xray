{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48e94110-810b-44f0-9e9c-34309fc5d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, float32\n",
    "from dataset.chestxray import ChestXRayDataset\n",
    "from datahandling.dataloader import get_list_from_txt, extract_annotation_targets\n",
    "from datahandling.transforms import to_numeric_label\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import  load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c6f1dfd-0872-48db-aa0f-6eb6a348c212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False /cluster/home/larsira/tdt4900/databases/chest_xray14 images\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "debug = ast.literal_eval(os.getenv(\"DEBUG\"))\n",
    "db_path = os.getenv(\"DB_PATH\")\n",
    "img_dir_name = os.getenv(\"IMG_DIR\")\n",
    "class_file_name = os.getenv(\"CLASSIFICATION_FILE\")\n",
    "train_list = os.getenv(\"TRAIN_VAL_LIST\")\n",
    "test_list = os.getenv(\"TEST_LIST\")\n",
    "\n",
    "img_dir = os.path.join(db_path, img_dir_name)\n",
    "print(debug, db_path, img_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f24f3d7b-0a84-4683-a0e1-271cef66c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = os.path.join(db_path, class_file_name)\n",
    "annotations = pd.read_csv(annotations_file)\n",
    "\n",
    "train_images = get_list_from_txt(os.path.join(db_path, train_list))\n",
    "test_images = get_list_from_txt(os.path.join(db_path, test_list))\n",
    "\n",
    "train_annotations = extract_annotation_targets(annotations, \"Image Index\", train_images)\n",
    "test_annotations = extract_annotation_targets(annotations, \"Image Index\", test_images)\n",
    "\n",
    "# Create relevant annotation files\n",
    "train_annotation_file = os.path.join(db_path, \"train.csv\")\n",
    "test_annotation_file = os.path.join(db_path, \"test.csv\")\n",
    "train_annotations.to_csv(train_annotation_file, index=False)\n",
    "test_annotations.to_csv(test_annotation_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "924aed80-be1d-4f70-b9f5-83a19aa6e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image and verify it's existence, and check a label\n",
    "\n",
    "if debug:\n",
    "    image = Image.open(os.path.join(img_dir, \"00000001_000.png\"))\n",
    "    print(annotations.iloc[0])\n",
    "    print(\"This patient is aflicted with:\", annotations[\"Finding Labels\"])\n",
    "    print(image)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ada3f6-a6b9-409f-a8d3-b58c5648cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set([x for y in [x.split(\"|\") for x in annotations[\"Finding Labels\"]] for x in y])\n",
    "labels.remove(\"No Finding\")\n",
    "\n",
    "if debug:\n",
    "    print(labels, \"There are\", len(labels), \"labels available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bc44627-7938-43af-ab8c-c05486f0c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ConvertImageDtype(float32),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = ChestXRayDataset(train_annotation_file, img_dir, labels, transform, to_numeric_label)\n",
    "train_loader = DataLoader(train_dataset, batch_size)\n",
    "\n",
    "test_dataset = ChestXRayDataset(test_annotation_file, img_dir, labels, transform, to_numeric_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size)\n",
    "if debug:\n",
    "    for idx, value in enumerate(loader):\n",
    "        test_img, test_lab = value\n",
    "        img = test_img[0]\n",
    "        label = test_lab[0]\n",
    "        if idx == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac261e31-5885-42f2-9190-63cf1c64c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet101(weights=None)\n",
    "model.fc = nn.Linear(2048, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da3a1c70-8d68-444a-8a09-a23d485ab482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "lr = 10e-4\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(idx, data_loader):\n",
    "    prev_loss = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print(\"batch {} loss: {}\".format(i+1, last_loss))\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b77fd6-961e-4699-8cb5-5f3115e307dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: profile 'ICC Profile': 'GRAY': Gray color space not permitted on RGB PNG\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "best_loss = 10_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "\n",
    "    avg_loss = train_epoch(epoch, train_loader)\n",
    "\n",
    "    running_validation_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            validation_inputs, validation_labesl = vdata\n",
    "            validation_output = model(validation_inputs)\n",
    "            validation_loss = loss_fn(validation_outputs, validation_inputs)\n",
    "            running_validation_loss += validation_loss\n",
    "    avg_validation_loss = running_validation_loss/(i+1)\n",
    "\n",
    "    if avg_validation_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"model_{}_{}\".format(epoch, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
