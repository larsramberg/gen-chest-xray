{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e372d865-a79c-4666-826d-ac08ae788bc1",
   "metadata": {},
   "source": [
    "Import and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056c6af8-112c-459c-b003-c3022c9db07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, float32\n",
    "from dataset.chestxray import ChestXRayDataset\n",
    "from datahandling.dataloader import get_list_from_txt, extract_annotation_targets\n",
    "from datahandling.transforms import to_numeric_label\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import  load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45674c6c-cab1-4306-ad87-810aa009d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False D:\\repos\\_databases\\chest-xray14 images\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "debug = ast.literal_eval(os.getenv(\"DEBUG\"))\n",
    "db_path = os.getenv(\"DB_PATH\")\n",
    "img_dir_name = os.getenv(\"IMG_DIR\")\n",
    "class_file_name = os.getenv(\"CLASSIFICATION_FILE\")\n",
    "\n",
    "img_dir = os.path.join(db_path, img_dir_name)\n",
    "print(debug, db_path, img_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61661b72-bd3f-4787-85bf-a52fa5eac420",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = os.path.join(db_path, class_file_name)\n",
    "annotations = pd.read_csv(annotations_file)\n",
    "\n",
    "train_images = get_list_from_txt(os.path.join(db_path, \"train-val-list.txt\"))\n",
    "test_images = get_list_from_txt(os.path.join(db_path, \"test-list.txt\"))\n",
    "\n",
    "train_annotations = extract_annotation_targets(annotations, \"Image Index\", train_images)\n",
    "test_annotations = extract_annotation_targets(annotations, \"Image Index\", test_images)\n",
    "\n",
    "# Create relevant annotation files\n",
    "train_annotation_file = os.path.join(db_path, \"train.csv\")\n",
    "test_annotation_file = os.path.join(db_path, \"test.csv\")\n",
    "train_annotations.to_csv(train_annotation_file, index=False)\n",
    "test_annotations.to_csv(test_annotation_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367fd53-7edb-45f1-9827-e36ba116fb0b",
   "metadata": {},
   "source": [
    "Sanity check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3127a0-b224-4ebe-aa4d-e0d9643e8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image and verify it's existence, and check a label\n",
    "\n",
    "if debug:\n",
    "    image = Image.open(os.path.join(img_dir, \"00000001_000.png\"))\n",
    "    print(annotations.iloc[0])\n",
    "    print(\"This patient is aflicted with:\", annotations[\"Finding Labels\"])\n",
    "    print(image)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4408df-b60f-45a0-b148-60112b657b3a",
   "metadata": {},
   "source": [
    "Fetch relevant labels from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d99a098-753a-4ab1-b6fb-08c04fe3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set([x for y in [x.split(\"|\") for x in annotations[\"Finding Labels\"]] for x in y])\n",
    "labels.remove(\"No Finding\")\n",
    "\n",
    "if debug:\n",
    "    print(labels, \"There are\", len(labels), \"labels available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8c622-407c-4586-ae8f-1c2763973ab3",
   "metadata": {},
   "source": [
    "Load into dataset, define a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53d5c1d-cd8f-4af4-b542-a8e32d58e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ConvertImageDtype(float32),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = ChestXRayDataset(train_annotation_file, img_dir, labels, transform, to_numeric_label)\n",
    "train_loader = DataLoader(train_dataset, batch_size)\n",
    "\n",
    "test_dataset = ChestXRayDataset(test_annotation_file, img_dir, lagbels, transform, to_numeric_label)\n",
    "test_loader = DataLoader(test_dataset, batch_size)\n",
    "if debug:\n",
    "    for idx, value in enumerate(loader):\n",
    "        test_img, test_lab = value\n",
    "        img = test_img[0]\n",
    "        label = test_lab[0]\n",
    "        if idx == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e72e4a-1d0b-4359-aecd-818ad6d04c4b",
   "metadata": {},
   "source": [
    "So here, we should probably define ourselves a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "290fbdbe-3cb9-419d-a1f9-3da62c887897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet101(weights=None)\n",
    "model.fc = nn.Linear(2048, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ab9d3c-ec55-48ad-b02d-924380771ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "lr = 10e-4\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(idx, data_loader):\n",
    "    prev_loss = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print(\"batch {} loss: {}\".format(i+1, last_loss))\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cb4fd06-6845-4efc-bf87-26195374be2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_numeric_label() missing 1 required positional argument: 'target_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     running_validation_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(idx, data_loader)\u001b[0m\n\u001b[0;32m      8\u001b[0m prev_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lars_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\lars_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\lars_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\lars_\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\repos\\gen-chest-xray\\dataset\\chestxray.py:26\u001b[0m, in \u001b[0;36mChestXRayDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     24\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform:\n\u001b[1;32m---> 26\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
      "\u001b[1;31mTypeError\u001b[0m: to_numeric_label() missing 1 required positional argument: 'target_labels'"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "best_loss = 10_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "\n",
    "    avg_loss = train_epoch(epoch, train_loader)\n",
    "\n",
    "    running_validation_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            validation_inputs, validation_labesl = vdata\n",
    "            validation_output = model(validation_inputs)\n",
    "            validation_loss = loss_fn(validation_outputs, validation_inputs)\n",
    "            running_validation_loss += validation_loss\n",
    "    avg_validation_loss = running_validation_loss/(i+1)\n",
    "\n",
    "    if avg_validation_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"model_{}_{}\".format(epoch, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
