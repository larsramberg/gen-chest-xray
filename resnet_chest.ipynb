{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e372d865-a79c-4666-826d-ac08ae788bc1",
   "metadata": {},
   "source": [
    "Import and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056c6af8-112c-459c-b003-c3022c9db07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim, float32, IntTensor, FloatTensor\n",
    "from dataset.chestxray import ChestXRayDataset\n",
    "from datahandling.dataloader import get_list_from_txt, extract_annotation_targets\n",
    "from datahandling.transforms import to_numeric_label\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from dotenv import  load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45674c6c-cab1-4306-ad87-810aa009d6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False E:/repos/chest-xray14 images\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "debug = ast.literal_eval(os.getenv(\"DEBUG\"))\n",
    "db_path = os.getenv(\"DB_PATH\")\n",
    "img_dir_name = os.getenv(\"IMG_DIR\")\n",
    "\n",
    "img_dir = os.path.join(db_path, img_dir_name)\n",
    "print(debug, db_path, img_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61661b72-bd3f-4787-85bf-a52fa5eac420",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_file = os.path.join(db_path, \"data_list.csv\")\n",
    "annotations = pd.read_csv(annotations_file)\n",
    "\n",
    "train_images = get_list_from_txt(os.path.join(db_path, \"train_val_list.txt\"))\n",
    "test_images = get_list_from_txt(os.path.join(db_path, \"test_list.txt\"))\n",
    "\n",
    "train_annotations = extract_annotation_targets(annotations, \"Image Index\", train_images)\n",
    "test_annotations = extract_annotation_targets(annotations, \"Image Index\", test_images)\n",
    "\n",
    "train_annotation_file = os.path.join(db_path, \"train.csv\")\n",
    "test_annotation_file = os.path.join(db_path, \"test.csv\")\n",
    "train_annotations.to_csv(train_annotation_file)\n",
    "test_annotations.to_csv(test_annotation_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367fd53-7edb-45f1-9827-e36ba116fb0b",
   "metadata": {},
   "source": [
    "Sanity check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed3127a0-b224-4ebe-aa4d-e0d9643e8a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first image and verify it's existence, and check a label\n",
    "\n",
    "if debug:\n",
    "    image = Image.open(os.path.join(img_dir, \"00000001_000.png\"))\n",
    "    print(annotations.iloc[0])\n",
    "    print(\"This patient is aflicted with:\", annotations[\"Finding Labels\"])\n",
    "    print(image)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4408df-b60f-45a0-b148-60112b657b3a",
   "metadata": {},
   "source": [
    "Fetch relevant labels from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d99a098-753a-4ab1-b6fb-08c04fe3522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set([x for y in [x.split(\"|\") for x in annotations[\"Finding Labels\"]] for x in y])\n",
    "labels.remove(\"No Finding\")\n",
    "\n",
    "if debug:\n",
    "    print(labels, \"There are\", len(labels), \"labels available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8c622-407c-4586-ae8f-1c2763973ab3",
   "metadata": {},
   "source": [
    "Load into dataset, define a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f53d5c1d-cd8f-4af4-b542-a8e32d58e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ConvertImageDtype(float32),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = ChestXRayDataset(train_annotation_file, img_dir, transform, to_numeric_label)\n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "\n",
    "test_dataset = ChestXRayDataset(test_annotation_file, img_dir, transform, to_numeric_label)\n",
    "test_loader = DataLoader(dataset, batch_size)\n",
    "if debug:\n",
    "    for idx, value in enumerate(loader):\n",
    "        test_img, test_lab = value\n",
    "        img = test_img[0]\n",
    "        label = test_lab[0]\n",
    "        if idx == 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e72e4a-1d0b-4359-aecd-818ad6d04c4b",
   "metadata": {},
   "source": [
    "So here, we should probably define ourselves a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "290fbdbe-3cb9-419d-a1f9-3da62c887897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet101(weights=None)\n",
    "model.fc = nn.Linear(2048, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23ab9d3c-ec55-48ad-b02d-924380771ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper params\n",
    "lr = 10e-4\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_epoch(idx, data_loader):\n",
    "    prev_loss = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000\n",
    "            print(\"batch {} loss: {}\".format(i+1, last_loss))\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1cb4fd06-6845-4efc-bf87-26195374be2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m(epoch, train_loader)\n\u001b[0;32m      9\u001b[0m     running_validation_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "best_loss = 10_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train(True)\n",
    "\n",
    "    avg_loss = train_epoch(epoch, train_loader)\n",
    "\n",
    "    running_validation_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            validation_inputs, validation_labesl = vdata\n",
    "            validation_output = model(validation_inputs)\n",
    "            validation_loss = loss_fn(validation_outputs, validation_inputs)\n",
    "            running_validation_loss += validation_loss\n",
    "    avg_validation_loss = running_validation_loss/(i+1)\n",
    "\n",
    "    if avg_validation_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"model_{}_{}\".format(epoch, epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
